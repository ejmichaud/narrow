\begin{table}[t]
\centering
\caption{Downstream task performance of pruned models before and after fine-tuning.}
\label{tab:pruned_results}
\begin{tabular}{@{}llrrrrrrrrrr@{}}
\toprule
\textbf{Method} & \textbf{Sparsity} & \multicolumn{2}{c}{CounterFact} & \multicolumn{2}{c}{AI2-ARC} & \multicolumn{2}{c}{WMDP-Bio} & \multicolumn{2}{c}{WMDP-Cyber} & \multicolumn{2}{c}{WMDP-Chem} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10} \cmidrule(lr){11-12}
& & Base & FT & Base & FT & Base & FT & Base & FT & Base & FT \\
\midrule
Base & 0% & 0.177 & 0.490 & 0.650 & 0.673 & 0.522 & 0.620 & 0.352 & 0.593 & 0.244 & 0.280 \\
\midrule
Random & 30% & 0.000 & 0.496 & 0.245 & 0.248 & 0.216 & 0.275 & 0.274 & 0.271 & 0.244 & 0.244 \\
 & 63% & 0.000 & 0.448 & 0.252 & 0.253 & 0.231 & 0.275 & 0.261 & 0.281 & 0.244 & 0.244 \\
 & 80% & 0.000 & 0.416 & 0.259 & 0.252 & 0.263 & 0.278 & 0.226 & 0.264 & 0.244 & 0.268 \\
\midrule
Attribution & 30% & 0.115 & 0.646 & 0.355 & 0.688 & 0.361 & 0.561 & 0.274 & 0.548 & 0.366 & 0.244 \\
 & 63% & 0.017 & 0.522 & 0.253 & 0.303 & 0.227 & 0.341 & 0.264 & 0.319 & 0.268 & 0.305 \\
 & 80% & 0.003 & 0.467 & 0.249 & 0.253 & 0.231 & 0.275 & 0.256 & 0.276 & 0.256 & 0.317 \\
\midrule
Group Lasso & 30% & 0.065 & 0.470 & 0.253 & 0.248 & 0.235 & 0.306 & 0.261 & 0.274 & 0.244 & 0.244 \\
 & 63% & 0.035 & 0.447 & 0.251 & 0.248 & 0.239 & 0.294 & 0.274 & 0.296 & 0.268 & 0.305 \\
 & 80% & 0.016 & 0.442 & 0.251 & 0.248 & 0.235 & 0.286 & 0.264 & 0.291 & 0.256 & 0.244 \\
\bottomrule
\end{tabular}
\end{table}