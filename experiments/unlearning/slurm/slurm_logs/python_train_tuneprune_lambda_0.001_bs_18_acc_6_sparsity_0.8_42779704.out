Training tuneprune_lambda_0.001_bs_18_acc_6_sparsity_0.8 on Python code
Input model: /n/netscratch/iaifi_lab/Lab/ericjm/narrow/tuneprune_pruned/lambda_0.001_bs_18_acc_6_sparsity_0.8
Output: /n/netscratch/iaifi_lab/Lab/ericjm/narrow/python_trained/tuneprune_lambda_0.001_bs_18_acc_6_sparsity_0.8

================================================================================
Training Pruned Model on Python Code
================================================================================
Model: /n/netscratch/iaifi_lab/Lab/ericjm/narrow/tuneprune_pruned/lambda_0.001_bs_18_acc_6_sparsity_0.8
Output: /n/netscratch/iaifi_lab/Lab/ericjm/narrow/python_trained/tuneprune_lambda_0.001_bs_18_acc_6_sparsity_0.8
Max steps: 10000
Save steps: 2500
Convert to variable size: True
================================================================================

Loading model...
Converting to VariableSizeLlamaForCausalLM...
  Original parameters: 1,235,814,400
  New parameters: 591,572,992
  Reduction: 52.1%
Loading Python code dataset (this may take a while on first run)...

Job completed at Wed Oct 22 17:34:39 EDT 2025
