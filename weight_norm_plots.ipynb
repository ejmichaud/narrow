{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    \"\"\"\n",
    "    Loads a finetuned Llama model from a checkpoint path.\n",
    "    This uses the Hugging Face AutoModelForCausalLM loader.\n",
    "    \"\"\"\n",
    "    # Note: The AutoModelForCausalLM.from_pretrained() call can load either a local directory or a hub ID.\n",
    "    model = AutoModelForCausalLM.from_pretrained(checkpoint_path, torch_dtype=torch.float16)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    # Optionally, move to CPU if desired: model.to(\"cpu\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_neuron_weight_norms(model):\n",
    "    \"\"\"\n",
    "    Computes neuron weight norms for each MLP layer in the model.\n",
    "    \n",
    "    For each layer, the neuron weight norm is computed as:\n",
    "    \n",
    "        norm = sqrt( sum(gate_proj.weight^2, dim=1)\n",
    "                   + sum(up_proj.weight^2, dim=1)\n",
    "                   + sum(down_proj.weight^2, dim=0) )\n",
    "    \n",
    "    This function assumes that the model has an attribute 'model.layers', where each layer\n",
    "    has an 'mlp' module with 'gate_proj', 'up_proj' and 'down_proj' projection layers.\n",
    "    \"\"\"\n",
    "    neuron_norms_all = []\n",
    "    \n",
    "    # Loop over layers. For Llama models the transformer layers live in model.model.layers.\n",
    "    # If needed, adjust this for your particular architecture.\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        # Access the three projection layers in the MLP component of each transformer layer.\n",
    "        gate_proj = layer.mlp.gate_proj\n",
    "        up_proj = layer.mlp.up_proj\n",
    "        down_proj = layer.mlp.down_proj\n",
    "\n",
    "        # Compute the L2 (Euclidean) norm for each neuron:\n",
    "        # - For gate_proj and up_proj, each row corresponds to a neuron so we sum over dim=1.\n",
    "        # - For down_proj, since weight.shape is [embedding_dim, hidden_dim],\n",
    "        #   we sum over dim=0 so that each neuron corresponds to a column.\n",
    "        neuron_norms_layer = torch.sqrt(\n",
    "            gate_proj.weight.pow(2).sum(dim=1) +\n",
    "            up_proj.weight.pow(2).sum(dim=1) +\n",
    "            down_proj.weight.pow(2).sum(dim=0)\n",
    "        )\n",
    "        neuron_norms_all.append(neuron_norms_layer.detach().cpu())\n",
    "    \n",
    "    # Concatenate norms from all layers into a single tensor and convert to numpy.\n",
    "    all_norms = torch.cat(neuron_norms_all, dim=0).numpy()\n",
    "    return all_norms\n",
    "\n",
    "def plot_norm_distribution(norms):\n",
    "    \"\"\"\n",
    "    Plots the histogram of neuron weight norms and prints some global quantiles.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(norms, bins=100, density=True, alpha=0.75)\n",
    "    plt.xlabel(\"Neuron Weight Norm\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Distribution of Neuron Weight Norms\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Compute and print several global percentiles.\n",
    "    norms_tensor = torch.tensor(norms)\n",
    "    percentiles = [1,5, 10, 25, 50, 75, 90, 95]\n",
    "    print(\"Global neuron weight norm percentiles:\")\n",
    "    for p in percentiles:\n",
    "        q_value = torch.quantile(norms_tensor, p / 100.0).item()\n",
    "        print(f\"  {p}th percentile: {q_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n"
     ]
    }
   ],
   "source": [
    "print(\"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2afc0b3a8a4fd9890f7e458c4a810a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /afs/csail.mit.edu/u/a/asher/narrow/experiments/weightpruning1/logs/checkpoint-2000 were not used when initializing LlamaForCausalLM: {'model.layers.2.mlp.up_proj.weight_mask', 'model.layers.14.mlp.up_proj.weight_orig', 'model.layers.1.mlp.up_proj.weight_orig', 'model.layers.8.mlp.gate_proj.weight_mask', 'model.layers.14.mlp.gate_proj.weight_mask', 'model.layers.6.mlp.gate_proj.weight_orig', 'model.layers.5.mlp.down_proj.weight_orig', 'model.layers.13.mlp.gate_proj.weight_orig', 'model.layers.13.mlp.down_proj.weight_orig', 'model.layers.6.mlp.down_proj.weight_orig', 'model.layers.0.mlp.up_proj.weight_orig', 'model.layers.7.mlp.down_proj.weight_mask', 'model.layers.15.mlp.up_proj.weight_orig', 'model.layers.5.mlp.up_proj.weight_mask', 'model.layers.14.mlp.down_proj.weight_mask', 'model.layers.11.mlp.gate_proj.weight_orig', 'model.layers.11.mlp.up_proj.weight_mask', 'model.layers.14.mlp.up_proj.weight_mask', 'model.layers.15.mlp.down_proj.weight_mask', 'model.layers.2.mlp.down_proj.weight_orig', 'model.layers.12.mlp.gate_proj.weight_mask', 'model.layers.0.mlp.gate_proj.weight_mask', 'model.layers.6.mlp.down_proj.weight_mask', 'model.layers.3.mlp.gate_proj.weight_orig', 'model.layers.5.mlp.gate_proj.weight_mask', 'model.layers.3.mlp.up_proj.weight_mask', 'model.layers.3.mlp.up_proj.weight_orig', 'model.layers.8.mlp.down_proj.weight_mask', 'model.layers.4.mlp.up_proj.weight_mask', 'model.layers.4.mlp.up_proj.weight_orig', 'model.layers.9.mlp.gate_proj.weight_orig', 'model.layers.12.mlp.down_proj.weight_orig', 'model.layers.2.mlp.down_proj.weight_mask', 'model.layers.13.mlp.up_proj.weight_mask', 'model.layers.6.mlp.up_proj.weight_orig', 'model.layers.9.mlp.down_proj.weight_orig', 'model.layers.0.mlp.up_proj.weight_mask', 'model.layers.3.mlp.gate_proj.weight_mask', 'model.layers.4.mlp.gate_proj.weight_orig', 'model.layers.9.mlp.down_proj.weight_mask', 'model.layers.10.mlp.down_proj.weight_mask', 'model.layers.12.mlp.down_proj.weight_mask', 'model.layers.2.mlp.gate_proj.weight_orig', 'model.layers.11.mlp.gate_proj.weight_mask', 'model.layers.3.mlp.down_proj.weight_mask', 'model.layers.5.mlp.up_proj.weight_orig', 'model.layers.13.mlp.down_proj.weight_mask', 'model.layers.8.mlp.up_proj.weight_mask', 'model.layers.14.mlp.gate_proj.weight_orig', 'model.layers.9.mlp.gate_proj.weight_mask', 'model.layers.0.mlp.gate_proj.weight_orig', 'model.layers.6.mlp.gate_proj.weight_mask', 'model.layers.4.mlp.gate_proj.weight_mask', 'model.layers.6.mlp.up_proj.weight_mask', 'model.layers.10.mlp.gate_proj.weight_mask', 'model.layers.8.mlp.up_proj.weight_orig', 'model.layers.10.mlp.down_proj.weight_orig', 'model.layers.4.mlp.down_proj.weight_mask', 'model.layers.14.mlp.down_proj.weight_orig', 'model.layers.11.mlp.up_proj.weight_orig', 'model.layers.12.mlp.up_proj.weight_orig', 'model.layers.1.mlp.down_proj.weight_mask', 'model.layers.2.mlp.up_proj.weight_orig', 'model.layers.15.mlp.up_proj.weight_mask', 'model.layers.11.mlp.down_proj.weight_mask', 'model.layers.10.mlp.up_proj.weight_orig', 'model.layers.9.mlp.up_proj.weight_orig', 'model.layers.12.mlp.up_proj.weight_mask', 'model.layers.7.mlp.gate_proj.weight_mask', 'model.layers.13.mlp.up_proj.weight_orig', 'model.layers.1.mlp.gate_proj.weight_mask', 'model.layers.4.mlp.down_proj.weight_orig', 'model.layers.2.mlp.gate_proj.weight_mask', 'model.layers.1.mlp.up_proj.weight_mask', 'model.layers.0.mlp.down_proj.weight_orig', 'model.layers.7.mlp.gate_proj.weight_orig', 'model.layers.1.mlp.gate_proj.weight_orig', 'model.layers.0.mlp.down_proj.weight_mask', 'model.layers.5.mlp.gate_proj.weight_orig', 'model.layers.7.mlp.down_proj.weight_orig', 'model.layers.7.mlp.up_proj.weight_mask', 'model.layers.12.mlp.gate_proj.weight_orig', 'model.layers.13.mlp.gate_proj.weight_mask', 'model.layers.1.mlp.down_proj.weight_orig', 'model.layers.10.mlp.up_proj.weight_mask', 'model.layers.15.mlp.down_proj.weight_orig', 'model.layers.9.mlp.up_proj.weight_mask', 'model.layers.3.mlp.down_proj.weight_orig', 'model.layers.8.mlp.gate_proj.weight_orig', 'model.layers.10.mlp.gate_proj.weight_orig', 'model.layers.15.mlp.gate_proj.weight_mask', 'model.layers.5.mlp.down_proj.weight_mask', 'model.layers.11.mlp.down_proj.weight_orig', 'model.layers.8.mlp.down_proj.weight_orig', 'model.layers.7.mlp.up_proj.weight_orig', 'model.layers.15.mlp.gate_proj.weight_orig'}\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /afs/csail.mit.edu/u/a/asher/narrow/experiments/weightpruning1/logs/checkpoint-2000 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/afs/csail.mit.edu/u/a/asher/narrow/experiments/weightpruning1/logs/checkpoint-2000\"\n",
    "model = load_model(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:9449/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "print(\"Computing neuron weight norms...\")\n",
    "norms = get_neuron_weight_norms(model)\n",
    "print(f\"Computed neuron weight norms for {len(norms)} neurons.\")\n",
    "plot_norm_distribution(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"jo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
